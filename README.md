# Traffic Intersection Simulation with Q-Learning

This project implements a smart trafficâ€‘light controller using **Q-Learning** together with a full **graphical simulation** built in Pygame. The system simulates a 4â€‘way intersection (North, South, East, West) where cars randomly arrive and the trafficâ€‘light agent learns when to keep the current light phase or switch phases to manage congestion more efficiently.

---

## ğŸ“ Project Structure

```
/project
â”‚
â”œâ”€â”€ simulation.py                # Full visual Pygame simulation
â”œâ”€â”€ car_manager.py               # Car spawning, movement & VIP logic
â”œâ”€â”€ traffic_controller.py        # Rule-based controller for simulation mode
â”œâ”€â”€ models.py                    # Data classes & enums
â”‚
â”œâ”€â”€ q_learning_env_advanced.py   # Training environment for RL
â”œâ”€â”€ train_q_learning_advanced.py # Q-learning training loop (updated rewards & metrics)
â”œâ”€â”€ q_table_advanced.json        # Learned Q-table saved after training
â”‚
â”œâ”€â”€ training_metrics.json        # Reward, queue, and switch metrics from training
â”œâ”€â”€ analysis.py                  # Generates graphs from RL training performance
â”‚
â”œâ”€â”€ reward_plot.png              # RL reward curve
â”œâ”€â”€ queue_plot.png               # Average queue size per episode
â”œâ”€â”€ switch_plot.png              # Phase switching metrics
â”‚
â””â”€â”€ README.md                    # Project documentation
```

---

## ğŸš¦ Project Overview

The goal is to create a realistic traffic-light system capable of adapting to realâ€‘time congestion. The project has two major components:

### â­ **1. Reinforcement Learning (Q-Learning) Agent**
The agent learns when to **keep** or **switch** the green light between:
- **NS (Northâ€“South)**
- **EW (Eastâ€“West)**

State features include:
- Discretized queue lengths (N, S, E, W)
- Current light phase
- Duration of current green phase
- Traffic imbalance between axes

Rewards encourage:
- Reducing queues  
- Avoiding excessive switching  
- Preventing extreme congestion  

After training, the agentâ€™s learned values are stored in `q_table_advanced.json`.

---

### â­ **2. Visual Traffic Simulator (Pygame)**

`simulation.py` displays a full intersection:
- Cars spawn from all directions with realistic spacing  
- **VIP vehicles** (ambulances, police, firefighters) get automatic greenâ€‘light priority  
- Smooth movement and lane-based positioning  
- Realistic yellow/green/red timing  
- A control panel showing queue counts and timers  

The simulation currently uses a **rule-based** traffic controller, not the RL agent. Integrating RL into the live simulation is suggested future work.

---

## ğŸ“Š Reinforcement Learning Metrics

Running:

```
python train_q_learning_advanced.py
```

produces:
- `training_metrics.json`
- `reward_plot.png`
- `queue_plot.png`
- `switch_plot.png`

You can analyze them with:

```
python analysis.py
```

### Example Conclusions
- Rewards improve significantly over training (from ~â€“300 to ~â€“230).  
- Average queues decrease and stabilize.  
- Phase switching becomes less erratic and more consistent.  

These results show that the agent is learning a more efficient and stable trafficâ€‘light policy.

---

## â–¶ï¸ How to Run the Simulation

### 1. Install dependencies
```
pip install pygame matplotlib
```

### 2. Run the visual simulation
```
python simulation.py
```

Controls:
- **UP/DOWN** â†’ change spawn rate  
- **R** â†’ reset simulation  

VIP cars automatically trigger green-light priority.

---

## â–¶ï¸ How to Train the Q-Learning Model

```
python train_q_learning_advanced.py
```
---
